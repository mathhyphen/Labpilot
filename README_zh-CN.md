[English](README.md) | **ç®€ä½“ä¸­æ–‡**

# LabPilot - AI é©±åŠ¨çš„è½»é‡çº§å®éªŒç®¡ç†åŠ©æ‰‹

LabPilot æ˜¯ä¸“ä¸ºæ·±åº¦å­¦ä¹ ç ”ç©¶è€…è®¾è®¡çš„æç®€å®éªŒç®¡ç†å·¥å…·ã€‚å‘Šåˆ«ç¹ççš„æ‰‹åŠ¨è®°å½•ï¼ŒLabPilot è‡ªåŠ¨å¸®ä½ ç®¡ç†ä»£ç ç‰ˆæœ¬ã€ç›‘æ§å®éªŒçŠ¶æ€ï¼Œå¹¶é€šè¿‡ AI è‡ªåŠ¨ç”Ÿæˆæäº¤ä¿¡æ¯ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **ğŸ¤– AI è¾…åŠ© Git**ï¼šè‡ªåŠ¨æ£€æµ‹ä»£ç å˜åŠ¨ï¼Œè°ƒç”¨å¤§æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæ¸…æ™°çš„ Git Commit Message å¹¶è‡ªåŠ¨æäº¤ã€‚
- **ğŸ“Š è‡ªåŠ¨å®éªŒè·Ÿè¸ª**ï¼šä¸€é”®è¿è¡Œï¼Œè‡ªåŠ¨è®°å½•å‘½ä»¤ã€å‚æ•°ã€æ—¶é—´ã€Git ç‰ˆæœ¬å’Œè¿è¡Œç»“æœã€‚
- **ğŸ” æ˜¾å¡æ£€æµ‹**ï¼šè‡ªåŠ¨æ£€æµ‹å¯ç”¨æ˜¾å¡ï¼Œè®°å½• GPU ä¿¡æ¯ï¼ˆNVIDIAã€AMDï¼‰ï¼Œä¸ºå®éªŒæä¾›æ›´å¥½çš„ç¡¬ä»¶ç¯å¢ƒè®°å½•ã€‚
- **ğŸ“± å®æ—¶é€šçŸ¥**ï¼šæ”¯æŒ **DingTalk (é’‰é’‰)** å’Œ **ntfy**ï¼Œéšæ—¶éšåœ°æŒæ¡å®éªŒè¿›åº¦ã€‚
- **ğŸŒ å¤šæœåŠ¡å™¨æ”¯æŒ**ï¼šæ”¯æŒè‡ªå®šä¹‰æœåŠ¡å™¨åç§°ï¼Œé›†ä¸­ç®¡ç†å¤šå°æœºå™¨çš„å®éªŒè®°å½•ã€‚
- **âš¡ï¸ é›¶ä¾µå…¥**ï¼šæ— éœ€ä¿®æ”¹ä»£ç ï¼Œåªéœ€åœ¨å‘½ä»¤å‰åŠ ä¸Š `labrun`ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
git clone https://github.com/mathhyphen/Labpilot.git
cd Labpilot
pip install -e .
```

### 2. é…ç½®

LabPilot æ”¯æŒ `.labpilot.yaml` (å½“å‰ç›®å½•) æˆ– `~/.labpilot.yaml` (ç”¨æˆ·ç›®å½•)ã€‚

**æ¨èé…ç½®ï¼š**

```yaml
# æœåŠ¡å™¨åç§°ï¼ˆå¤šæœåŠ¡å™¨åœºæ™¯éå¸¸æœ‰ç”¨ï¼‰
server_name: "GPU-Server-01"

# AI è‡ªåŠ¨ Commit é…ç½® (æ”¯æŒ OpenAI æ ¼å¼ API)
ai:
  api_key: "your-api-key"
  base_url: "https://open.bigmodel.cn/api/paas/v4/" # é»˜è®¤æ™ºè°± AIï¼Œå¯æ¢æˆå…¶ä»– OpenAI å…¼å®¹æ¥å£
  model: "glm-4"

# é€šçŸ¥é…ç½®
notification:
  active: [dingtalk] # æˆ– [dingtalk, ntfy]
  dingtalk:
    webhook_url: "https://oapi.dingtalk.com/robot/send?access_token=..."
```

### 3. ä½¿ç”¨

å°±åƒä½¿ç”¨ `nohup` æˆ– `sudo` ä¸€æ ·ï¼Œåœ¨ä½ çš„è®­ç»ƒå‘½ä»¤å‰åŠ ä¸Š `labrun`ï¼š

```bash
# è¿è¡Œè®­ç»ƒè„šæœ¬
labrun python train.py --epochs 100 --lr 1e-4

# æŒ‡å®šè¶…æ—¶æ—¶é—´ï¼ˆä¾‹å¦‚ 5 å°æ—¶åè‡ªåŠ¨åœæ­¢ï¼‰
labrun --timeout 18000 python train.py

# ç­‰å¾…æ˜¾å­˜è¶³å¤Ÿçš„GPUï¼ˆä¾‹å¦‚ç­‰å¾…ç©ºé—²æ˜¾å­˜ >12GB çš„GPUï¼‰
labrun --wait-gpu 12g python train.py --epochs 100 --lr 1e-4

# ç­‰å¾…æŒ‡å®šæ˜¾å­˜çš„GPUï¼ˆä»¥MBä¸ºå•ä½ï¼‰
labrun --wait-gpu 10240m python train.py --batch_size 64

# ç­‰å¾…ä»»ä½•å¯ç”¨çš„GPU
labrun --wait-gpu any python train.py --epochs 50
```

## ğŸ§  AI é©±åŠ¨çš„ Git æµç¨‹

LabPilot çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€æ˜¯**è‡ªåŠ¨åŒ–ç‰ˆæœ¬æ§åˆ¶**ã€‚å½“æ‚¨è¿è¡Œå®éªŒæ—¶ï¼š

1. æ£€æµ‹å½“å‰ä»£ç æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹ã€‚
2. å¦‚æœæœ‰æ›´æ”¹ï¼Œè‡ªåŠ¨æ”¶é›† `git diff`ã€‚
3. **è°ƒç”¨é…ç½®çš„ LLM API** åˆ†æä»£ç å˜åŠ¨ã€‚
4. ç”Ÿæˆè¯­ä¹‰åŒ–çš„ Commit Messageï¼ˆä¾‹å¦‚ï¼š"feat: add learning rate scheduler"ï¼‰ã€‚
5. è‡ªåŠ¨æ‰§è¡Œ `git commit` ä¿å­˜å®éªŒç°åœºå¿«ç…§ã€‚

è¿™ç¡®ä¿äº†æ‚¨çš„æ¯ä¸€æ¬¡å®éªŒè®°å½•éƒ½ä¸¥æ ¼å¯¹åº”å”¯ä¸€çš„ä»£ç ç‰ˆæœ¬ï¼Œä¸”æ‹¥æœ‰å¯è¯»çš„å†å²è®°å½•ã€‚

## ğŸ”§ é«˜çº§é…ç½®

### å¤šæœåŠ¡å™¨å…±äº«æ•°æ®

å°† `database.path` æŒ‡å‘å…±äº«å­˜å‚¨ï¼ˆå¦‚ NFSï¼‰ï¼š

```yaml
database:
  path: "/mnt/nfs/labpilot/shared.db"
```

### ntfy é€šçŸ¥é…ç½®

```yaml
notification:
  active: [ntfy]
  ntfy:
    topic: "my-secret-topic" # è®¢é˜…ä¸»é¢˜
    server: "https://ntfy.sh"
```

### æ˜¾å¡æ£€æµ‹å’Œè‡ªåŠ¨é€‰æ‹©

LabPilot è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„NVIDIAæ˜¾å¡å¹¶æä¾›æ™ºèƒ½GPUæ’é˜ŸåŠŸèƒ½ï¼š

**æ˜¾å­˜æ ¼å¼ç¤ºä¾‹ï¼š**
- `12g` = 12 GB
- `10240m` = 10240 MB
- `any` = ä»»ä½•å¯ç”¨çš„GPU

**å·¥ä½œåŸç†ï¼š**
1. ä½¿ç”¨ `nvidia-smi` æŸ¥è¯¢GPUæ˜¾å­˜çŠ¶æ€
2. æ‰¾åˆ°ç©ºé—²æ˜¾å­˜è¶³å¤Ÿçš„GPU
3. è‡ªåŠ¨è®¾ç½® `CUDA_VISIBLE_DEVICES` ç¯å¢ƒå˜é‡
4. ç­‰å¾…ç›´åˆ°åˆé€‚çš„GPUå¯ç”¨

**å‘½ä»¤ç¤ºä¾‹ï¼š**
```bash
# ç­‰å¾…ç©ºé—²æ˜¾å­˜ >8GB çš„GPU
labrun --wait-gpu 8g python train.py

# ç­‰å¾…ç©ºé—²æ˜¾å­˜ >16384MB çš„GPU
labrun --wait-gpu 16384m python train.py

# ä¸ç­‰å¾…GPUç›´æ¥è¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤GPUï¼‰
labrun python train.py

# ç»“åˆè¶…æ—¶è®¾ç½®ä½¿ç”¨
labrun --wait-gpu 12g --timeout 3600 python train.py
```

## ğŸ“Š Web ä»ªè¡¨æ¿

å¯åŠ¨å†…ç½®çš„ Web ç•Œé¢æŸ¥çœ‹æ‰€æœ‰å®éªŒå†å²ï¼š

```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000
```
